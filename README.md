# Scrapuba

[ES/EN]

La versi√≥n en ingl√©s de este README estar√° disponible pronto.

> ‚ÄúThe illiterate of the 21st century will not be those who cannot read and write, but those who cannot learn, unlearn and relearn.‚Äù  
‚Äì Alvin Toffler

> ‚ÄúTo develop a complete mind: study the science of art; study the art of science. Learn how to see. Realize that everything connects to everything else.‚Äù  
‚Äì Leonardo da Vinci

>‚ÄùEducating the masses was intended only to improve the relationship between the top and the bottom of society. Not for changing the nature of the relationship.‚Äù  
‚Äì John Ralston Paul, ‚ÄúVoltaire‚Äôs Bastards‚Äù

Scrapuba es un "bot" para descargar el material publico disponible en el [Campus Virtual de la Facultad de Ciencias Exactas de la UBA]([https://campus.exactas.uba.ar](https://campus.exactas.uba.ar/)).

Esta es la primera versi√≥n *funcional* del bot. Por mis intereses personales, el material que descargo es el del departamento de computaci√≥n, pero idealmente esto podr√≠a ser configurable en pr√≥ximas versiones. Por el momento si se desea descargar el material de otro departamento, se deber√° cambiar la URL dentro del c√≥digo.

**Disclaimer**: Esperen inestabilidad, la plataforma misma del campus es inestable. Si el bot no termina de correr al 100% la primera vez, try again. Si el problema esta en el c√≥digo, abrime un issue! De ese modo puedo solucionar el inconveniente y robustecer la automatizacion.

- [Naturaleza](#naturaleza)
  * [Highlights](#highlights)
- [Scrapuba NO es esto](#scrapuba-no-es-esto)
- [Instrucciones](#instrucciones)
  * [Requisitos](#requisitos)
  * [Instalacion](#instalacion)
  * [Uso](#uso)
- [Proximos pasos](#proximos-pasos)
- [Quiero colaborar](#quiero-colaborar)
- [Motivaciones](#motivaciones)
- [FAQs](#faqs)
- [License](#license)

## Naturaleza

Esta primera versi√≥n es capaz de:

- Recorrer el listado de a√±os y per√≠odos de cada a√±o, recolectando los nombres de las asignaturas  y el link hacia las mismas. El paginado es tenido en cuenta para que no queden asignaturas fuera.
Archivo encargado: `index.js`
- Con la informaci√≥n anterior, el pr√≥ximo paso es entrar en cada asignatura y recolectar el t√≠tulo y el link de cada tab disponible en dicha asignatura. 
Algunas asignaturas si bien nos permiten entrar a su campus, requieren autenticaci√≥n por lo que solamente nos van a mostrar el tab de "Inicio". 
Archivo encargado: `subjects.js`

> La informaci√≥n generada por los dos pasos anteriores est√°n guardadas en el archivo `data/crawled.json` (actualizado al d√≠a 2020-06-22)

- El tercer paso que era el objetivo de esta primera versi√≥n es leer el archivo `crawled.json` y recorrer materia por materia, tab por tab en busca de la descarga de los materiales disponibles (y los descarga si los hay en el path `downloads/${a√±o}/${materia}/${id}`).
Archivo encargado: `download.js`

En este tercer paso vale hacer una aclaraci√≥n sobre los tipos de descarga con los que me top√© en el campus. Esencialmente hay dos tipos de descargas:

1) Descargas de "carpetas de material", las cuales clickeamos el link y nos devuelven la carpeta con el material comprimido. 
Estas descargas de carpetas son las que busca el bot en esta versi√≥n. Si se quiere, tambi√©n se pueden descargar los materiales por separado, pero hay una limitaci√≥n t√©cnica de Puppeteer en cuanto a los archivos PDF, por lo que esto quedar√° para el futuro.

2) Descargas de archivos sueltos, en varios formatos que no hacen al caso. Dado que Puppeteer tiene limitaciones t√©cnicas en cuanto a la lectura, navegaci√≥n hacia y descarga de archivos PDF, este tipo de descargas van a ser implementados en el futuro.
Lo que se puede hacer f√°cilmente a corto plazo por lo menos es crawlear los links de estos materiales para tenerlos "a mano", independientemente de que tipo de archivo sean.

Nota: Hay algunos workarounds de Puppeteer en los cuales interceptando el request y haciendolo a mano se puede descargar el archivo PDF deseado. No es scope de esta version implementarlos, no me resultaron tan estables los que prob√©.

Referencias Puppeteer ‚Üî pdf:

- [https://github.com/puppeteer/puppeteer/issues/299](https://github.com/puppeteer/puppeteer/issues/299)

### Highlights
![Getting_Subjects_Info](demo.png)
![Downloading](demo.gif)

## Scrapuba NO es esto

Scrapuba NO es **nada** de lo siguiente, y cualquier uso del mismo para lograrlo es estrictamente anti √©tico y potencialmente ilegal.

- Una herramienta para perpetrar DDoS o para desestabilizar el sitio.
- Una herramienta para obtener informaci√≥n de docentes y/o alumnos de las c√°tedras.
- Una herramienta para obtener plataformas de comunicaci√≥n de las cursadas entre los alumnos y los responsables de la universidad.

Debido a la naturaleza autom√°tica de Puppeteer, es menester que haya delays entre las acciones en el sitio para no caer en situaciones del primer punto nombrado anteriormente.

## Instrucciones

### Requisitos

Node v12.18.1

### Instalacion

```bash
git clone https://github.com/lzok/scrapuba.git
cd scrapuba
npm i
```

### Uso

```bash
# Ya tenemos los datos necesarios en el archivo crawled.json asi que
# podemos ir directo a descargar material.
npm run download
```

## Proximos pasos

- Refactorizar c√≥digo para centralizar los selectores usados y usarlos como constantes. Tambi√©n hay c√≥digo repetido que se puede centralizar en funciones comunes.
No me gusta la cantidad de `for` que hay, pero era la forma r√°pida de *get the thing working right now.*
- Agregar linters y formateador de c√≥digo. En la pc que hice este proyecto no tengo nada configurado.
- Generar una serie de scripts por si se quisiera ejecutar el proceso completo de una sola vez, o bien solamente la parte de descargas.
- ~~Cambiar los `console.log` por Winston como sistema de logging.~~
- Hacer el error handling correspondiente.
- A√±adir opci√≥n de loguearse en caso de tener cuenta en el campus? Al ser autom√°tico pongo en duda proveer credenciales.
- Permitir configuraciones externas como pueden ser arrancar el bot en modo headless, cambiar la ruta de descargas por default, etc.
- Dadas las limitaciones t√©cnicas mencionadas de Puppeteer, guardar en un archivo JSON o de naturaleza similar todos los links que se correspondan con descargas de materiales individuales. El selector de esto ya est√° disponible.
- Resolver las limitaciones t√©cnicas de Puppeteer con alg√∫n workaround que sea **estable** para poder descargar archivos pdf individuales. En los issues de Github mencionan unos cuantos.
- Detectar bibliografias y/o materiales de referencia para poder guardarlos.

## Quiero colaborar

Genial!

Pod√©s tomar cualquiera de los puntos listados en **Pr√≥ximos pasos** y mandar un pr mostrando la soluci√≥n para mergearlo ac√°.

Si ning√∫n punto te interesa pero ten√©s m√°s ideas para sumar, son bienvenidas. Contactate conmigo que las charlamos para ponerlas en marcha.

## Motivaciones

Probar Puppeteer y ver qu√© ense√±an en CS en la UBA.

Conclusi√≥n Puppeteer: Sencillo de usar, s√∫per imperativo (ü§¢). Muy recomendado para tareas sencillas; se vuelve engorroso con usos m√°s complejos.
La documentaci√≥n de Puppeteer est√° muy bien lograda y completa.

## FAQs

- *Eh pero podr√≠as haberlo hecho con X que es rapid√≠simo y scrapea como un f√≥rmula 1 y sabe descargar pdfs sin workarounds y encima arregla las inconsistencias del sitio y te sirve caf√© mientras laburas.*

ü§ê

## License
**MIT LICENSE**

La licencia completa la podes chequear [aca](https://github.com/Lzok/scrapuba/blob/master/LICENSE)
